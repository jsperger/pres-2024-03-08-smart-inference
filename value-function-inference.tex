\documentclass[aspectratio=169, professionalfonts]{beamer}

\usepackage{graphicx}
\usepackage{subfig}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}

\usepackage{hyperref} \hypersetup{ colorlinks=true,
	linkcolor=blue, filecolor=magenta, urlcolor=cyan, pdftitle={Overleaf Example},
	pdfpagemode=FullScreen}

\input{components/combined-macros.tex}

\usepackage[style=verbose-ibid,backend=biber, isbn=false, url=false, doi=false,
	eprint=false, dashed=false]{biblatex}
\addbibresource{my-biblatex-library.bib}

% Assumed directory structure is structure both VK and its associated files
% live in ./components/vk-theme
\usepackage{components/vk-theme/beamerthemeVK}

\author{John Sperger}
\date{March 8\textsuperscript{th} 2024}
\title{Value Function Inference}
\subtitle{A Moderately Technical Introduction}
\begin{document}
\maketitle

\section{Overview}
\begin{frame}{Outline}
	\tableofcontents[hideallsubsections]
\end{frame}

\begin{frame}[label={overview:time}]{Inference for DTRs}

	Differences in temporal setup: Single-stage, Multi-stage, Infinite Horizon
	\vfill
	Assumptions about these settings, e.g. recent seminar speaker Chengchun
	Shi's work on testing the Markov Assumption in MDPs
	\vfill
	Estimands: model parameters, value-function-related, and SMARTs have
	multiple non-DTR
	\vfill \pause
	Today's focus: Value Function Inference in the Single-stage Setting
\end{frame}

% \begin{frame}{SMARTs and DTRs are not synonymous}
% \end{frame}

\begin{frame}[label={overview:objectives}]{Learning Objectives}
	At the end of today's talk you should be able to:
	\begin{itemize}
		\item Explain the fundamental challenge facing value function inference
		      that applies to all temporal settings.
		      %		\item Provide an example of other problems in statistics that face a similar hurdle
		\item Define the potential value function estimands and contrast the
		      reasons for choosing them.

		\item Summarize the asymptotic techniques used in value function inference.

		\item Identify alternative approaches to asymptotic inference for the
		      value function.
		      %		\item Explain inference for OWL
		      %		\item Name the keywords to search for to find relevant theory
	\end{itemize}
	\vfill
\end{frame}

\subsection{OWL}
\begin{frame}{OWL}
	\begin{figure}
		\includegraphics[width=.6\textwidth]{figures/how-to-draw-an-owl}
	\end{figure}
\end{frame}
\subsection{Notation}
\subsection{Math notation}
\begin{frame}[label={sec:org00d2d44}]{Notation}

	Let $[K]$ denote the set $\{1, \ldots, K \}$ for a positive integer $K$. Assume
	the data is comprised of iid replicates:

	\begin{equation}
		\left\{{\covarrv}_{\obsindex},\, {\armrv}_{\obsindex},\,
		{\resprv}_{\obsindex} \right\}_{\obsindex = 1}^{\maxobsindex}
	\end{equation}

	where
	\vfill \pause

	\begin{itemize}
		\item $\covarrv_{\obsindex} \in \covarspace \subseteq
			      \symbb{R}^{\dimarmparam}$ denotes the covariates (contexts)

		\item $\armrv_{ \obsindex} \in \armspace$ denotes the treatment arm (arm,
		      intervention, action)

		\item $\resprv_{ \obsindex} \in \symbb{R}$ denotes the response (reward)
	\end{itemize}

	\vfill \pause

	We'll use the potential outcome framework and denote the potential outcome 	$\po(\armobs)$

\end{frame}


\begin{frame}{Operator notation}
	\begin{itemize}
		\item $\covarrv_1, \ldots, \covarrv_{\maxobsindex}$ is an iid random sample from a
		      fixed but unknown distribution $\Pop$
		\item $\genericfun$ is a generic parametric function indexed by $\theta \in \Theta$
		\item $\hat{\theta} \in \Theta$ is a random variable constructed from the sample
		      $\covarrv_1, \ldots, \covarrv_{\maxasymindex}$
	\end{itemize}
	\vfill \pause

	$\Pop$ denotes the probability measure:
	\begin{equation*}
		\Pop \genericfun(\covarrv; \hat{\theta}) = \int \genericfun(\covarobs;\,\widehat{\theta}) \dv
		\Pop(\covarobs))
	\end{equation*}

	\vfill \pause $\Pn$ denotes the corresponding empirical measure:

	\begin{equation*}
		\Pn \genericfun(\covarrv; \hat{\theta}) = \asymindex^{-1}\sum_{i =
			1}^{\asymindex} \genericfun(\covarobs_{i};\,\hat{\theta})
	\end{equation*}
	\vfill \pause

	$\leadsto$ denotes convergence in distribution.

	\vfill
\end{frame}

\subsection{Treatment Policy Notation}

\begin{frame}{Treatment Policy Notation}
	A policy (aka DTR, treatment rule) $\pol$ maps contexts to actions $\pol: \covarspace \mapsto \armspace$.

	\vfill \pause
	The expected response given
	the covariates and arm assignment $\E[\resprv \vert \covarobs, \armobs =
			\armindex]$is given by $\meanfun(\covarobs, \armobs = \armindex) \equiv \meanfunk(x)$
	for some function $\meanfun \in \funclass$.

	\vfill \pause
	Define the value of a policy $\pol$ as
	\begin{equation}
		\val(\pol) = \E_{\covarrv}[\po(\armobs = \pol(\covarrv))]
	\end{equation}

	\vfill \pause
	An optimal policy $\optpol$ is any policy that satisfies
	\begin{equation}
		\val(\optpol) \geq \val(\pol) \qquad \text{for all }\pol \in \polset
	\end{equation}
\end{frame}

\begin{frame}{The Estimated Optimal Policy}
	Denote the estimated optimal policy $\polhatn$, and to simplify life assume
	that there is a unique maximizer for every covariate value, or more formally

	$$\text{For all} \covarrv \in \covarspace \text{ there exists an arm }k^*
		\text{ such that } \meanfun_{\armindex^*}(\covarrv) > \max_{\armindex \neq
			\armindex^*} \meanfunk(\covarrv)$$

	\vfill \pause
	This assumption ensures that the optimal policy is deterministic:
	$$\polopt(\covarobs) = \argmax_{\armindex \in [\maxarmindex]}\meanfunk(\covarobs)$$

	The estimated optimal policy
\end{frame}


\begin{frame}{Operator Notation Exercise}
	Rewrite the following in operator notation:
	\vfill
	\begin{itemize}

		\item Conditional Value of the estimated optimal policy

		      $$\E_{\covarrv}[\polhatn(\covarrv) \vert \polhatn] = ?$$

		\item Value of the optimal policy
		      $$\E_{\covarrv}[\optpol(\covarrv)] = ?$$

		\item Estimated Value of the optimal policy

		      $$\valhatn(\polhatn(\covarrv)) = ?$$
	\end{itemize}
	\vfill

\end{frame}

\begin{frame}{Operator Notation Exercise}
	Rewrite the following in operator notation:
	\vfill
	\begin{itemize}

		\item Conditional Value of the estimated optimal policy
		      \pause
		      $$\E_{\covarrv}[\polhatn(\covarrv) \vert \polhatn] = \Pop \polhatn(\covarrv)$$
		      \pause
		\item Value of the optimal policy
		      \pause
		      $$\E_{\covarrv}[\optpol(\covarrv)] = \Pop \optpol(\covarrv)$$
		      \pause
		\item Estimated Value of the estimated optimal policy
		      \pause
		      $$\valhatn(\polhatn(\covarrv)) = \Pn \val(\polhatn(\covarrv))$$
	\end{itemize}
	\vfill

\end{frame}


\begin{frame}{Operator Notation Exercise}
	Rewrite the following in operator notation:
	\vfill
	\begin{itemize}

		\item Conditional Value of the estimated optimal policy

		      $$\E_{\covarrv}[\polhatn(\covarrv) \vert \polhatn] = \Pop \polhatn(\covarrv)$$

		\item Value of the optimal policy
		      $$\E_{\covarrv}[\optpol(\covarrv)] = \Pop \optpol(\covarrv)$$
	\end{itemize}
	\vfill

\end{frame}

\section{Estimands and Inferential Targets}

\begin{frame}{Value Functions}
	\begin{enumerate}
		\item Conditional Value of the estimated optimal policy

		      $$\E_{\covarrv}[\polhatn(\covarrv) \vert \polhatn] = \Pop \polhatn(\covarrv)$$

		\item (Expected) Value of an estimated optimal policy
		      $$\E_{\covarrv}[\polhatn(\covarrv)]$$

		\item Value of the optimal policy
		      $$\E_{\covarrv}[\optpol(\covarrv)] = \Pop \optpol(\covarrv)$$
	\end{enumerate}

	\vfill \pause

	Are estimators of these functions asymptotically equivalent?

	\vfill \pause
	Brainstorm a scenario for each of the value functions where that estimand would
	make the most sense.
\end{frame}

\section{Nonregular Introduction}
\begin{frame}{Toy Problem: Max of Gaussian Means}
	Suppose we have a random iid sample of size $n$ where
	\begin{equation*}
		X_i \sim \MVN \left(\symbf{\mu} = \begin{pmatrix}2 \\ -1 \end{pmatrix},\, \Sigma = \begin{bmatrix}1 & 0
               \\ 0 & 1\end{bmatrix} \right)
	\end{equation*}

	\vfill
	\pause

	In the general case let $p$ denote the dimension of $\symbf{\mu}$ and assume
	that the covariance matrix is the identity matrix. Suppose we are interested
	in $\theta$:

	$$\theta = \max_{j \in
			[p]} \mu_j = \maxsym_{j = 1}^{p} \mu_j$$
	\vfill

	Here $\theta = \max \{2, -1\} = 2$

	\vfill
	\pause
	Let $$\hat{\theta}_n = \max_{j \in \{1, 2 \}} \Pn {X}_j $$
	\vfill
	\pause
	What is the limiting distribution of $\rootn (\hat{\theta} - \theta)$ for $\symbf{\mu} =
		(2, -1 )^{\trans}$?

	Hint: don't overthink it
\end{frame}

\begin{frame}{Max of Gaussian Means continued}
	A: $\rootn (\hat{\theta} - \theta) \convd \symtt{N}(0, 1)$
	\pause
	\vfill
	Suppose $\symbf{\mu} = (0 , 0)^{\trans}$

	Now what is the limiting distribution of $ \rootn (\hat{\theta} - \theta)$?

	\vfill \pause

	$$\rootn (\hat{\theta} - \theta) \convd \max(\symtt{N}(0, 1), \symtt{N}(0, 1))$$

	Now the limiting distribution is the maximum of two independent standard
	normal RVs.

	\vfill \pause

	Problem: the limiting distribution depends on the value of the parameter
	$\symbf{\mu}$

	\vfill

	To analyze the value function we'll need to address nonregular asymptotics.
\end{frame}


\subsection{Asymptotics --- What are we doing here?}
\begin{frame}{Why (when) do we trust asymptotic approximations?}
	Assuming standard regularity condition hold, what does the Central Limit
	Theorem tell us about $\Pn \covarrv$?

	Taylor Series
\end{frame}

\begin{frame}{Berry Essen Theorem}
	Suppose $\covarrv_1, \ldots, \covarrv_{\asymindex}$ are iid with
	\begin{align*}
		\E[X]     & = 0                 \\
		\E[X^2]   & = \sigma^2 < \infty \\
		\E[|X|^3] & = \rho < \infty
	\end{align*}
	And let $Y_{\asymindex} = \Pn \covarrv$. Then
	\vfill
	\begin{equation}
		\sup_{x \in \mathbb{R}}|F_{\asymindex}(\covarobs) - \Phi(\covarobs)| \leq \frac{C
			\rho}{\sigma^{3} \rootn }
	\end{equation}

	Where $C$ is a universal constant and according to the wiki I haven't fact
	checked our current best bounds are $.4097 \leq C \leq .4748$
	\vfill
\end{frame}

\begin{frame}{But wait --- aren't all treatment effects nonzero?}
	Even if the effect is $\epsilon^{-35}$ for some $\epsilon \ll 1$ we have asymptotic
	normality. Don't all treatments have an  effect at that level even if it's
	just the sugar in the pill?
\end{frame}



\section{Constructing Asymptotic Confidence Intervals}
\subsection{Projections}
\begin{frame}{Projection Region Big Picture}
	Recall our formulation $\theta_n = \theta_0 + h(n)s$
	\begin{enumerate}
		\item The empirical estimator $\widehat{\mu}_n = \Pn X$ is well-behaved (regular, asymptotically normal)
		\item If we knew $\mu_0$ forming confidence intervals for $\widehat{\mu}_n$
	\end{enumerate}
\end{frame}
\subsection{Bound-based}
\begin{frame}{Bound-based}
\end{frame}
\subsection{Bootstrap}
\begin{frame}{The $m$-out-of-$n$ Bootstrap}
\end{frame}

\begin{frame}{The Jackknife+}
\end{frame}

\subsection{Conformal Inference}
\begin{frame}{Jackknife+}
\end{frame}
\begin{frame}{What exactly is conformal inference guaranteeing}
\end{frame}
\section{Avoiding Nonregularity}
\begin{frame}{Alternatives to Asymptotics}
	If the blow-up happens in the limit, what if we just don't take it to the limit?


\end{frame}

\section{Where Next?}

\begin{frame}{Where to Start}
	\vfill

	Start with Chapter 10 of \cite{tsiatis2019Dynamic}
	\vfill

\end{frame}

\begin{frame}{General Theory -- Asymptotic}
	\vfill
	\begin{itemize}
		\item Chapter 3 of \cite{tsiatis2006Semiparametric}
		      \vfill
		\item Chapters 6 and 7 of \cite{vandervaart2000Asymptotic}
		      \vfill
		\item \cite{kosorok2008Introduction}
		      \vfill
		\item Important Paper: \cite{hirano2012Impossibility}
		      \vfill


		\item 	\cite{bibaut2021PostContextualBandit}
		      \vfill
	\end{itemize}
\end{frame}

\begin{frame}{Precision Medicine}
	\vfill
	\begin{itemize}
		\item \cite{laber2014Dynamic}
		      \vfill

		\item 	\cite{luedtke2016Statistical}
		      \vfill

		\item 	\cite{shi2022Statistical}

		\item \cite{hadad2021Confidence}
	\end{itemize}
	\vfill

\end{frame}

\begin{frame}{General Theory -- Non-asymptotic}
	\vfill
	\begin{itemize}
		\item \cite{waudby-smith2022Anytimevalid}
		      \vfill

		      \item\cite{howard2021Timeuniform}
	\end{itemize}
	\vfill


\end{frame}

\appendix
\printbibliography

\end{document}
%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: t
%%% End:
