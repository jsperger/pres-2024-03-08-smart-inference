\documentclass[aspectratio=169, professionalfonts]{beamer}
\usepackage{mathtools} % \mathclap for shortening overbrace text
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}

\usepackage{hyperref} \hypersetup{ colorlinks=true,
	linkcolor=blue, filecolor=magenta, urlcolor=cyan, pdftitle={Overleaf Example},
	pdfpagemode=FullScreen}

%% Personal macros across multiple projects
\input{components/combined-macros.tex}
%% Paper-specific macros
\newcommand{\prode}[2]{E_{#1}^{#2}}
\usepackage[style=verbose,backend=biber, isbn=false, url=false, doi=false,
	eprint=false, dashed=false]{biblatex}
\addbibresource{my-biblatex-library.bib}

% Assumed directory structure is structure both VK and its associated files
% live in ./components/vk-theme
\usepackage{components/vk-theme/beamerthemeVK}

\author{John Sperger}
\date{March 8\textsuperscript{th} 2024}
\title{Value Function Inference}
\subtitle{A Mildly Technical Introduction}
\begin{document}
\maketitle

\section{Introduction}
\begin{frame}{Outline}
	\tableofcontents[hideallsubsections]
\end{frame}
\begin{frame}[label={overview:objectives}]{Learning Objectives}
	%	We will cover: value function inference for a single-stage treatment policy /
	%	dynamic treatment regime (DTR)
	\vfill \pause
	At the end of today's talk you should be able to:
	\begin{itemize}
		\item Identify the fundamental challenge facing value function
		      inference		      that applies to all temporal settings.
		      \vfill \pause

		      %\item Provide an example of other problems in statistics that
		      %face a similar hurdle
		      %		\item Define the potential value function estimands and contrast the
		      %		      reasons for choosing them.

		\item Categorize the major approaches to inference in this setting

		      \vfill \pause

		\item Provide reasons when projection intervals may be preferable to
		      bootstrap intervals and vice versa.
		      \vfill \pause

		\item Explain the connection between the finite-sample approach and the
		      asymptotic approaches
		      %\item Explain inference for OWL
		      %\item Name the keywords to search for to find relevant theory
	\end{itemize}
	\vfill
\end{frame}

% \begin{frame}{Key concepts}
%     Smoothness
%     \end{frame}

\subsection{Math notation}
\begin{frame}[label={sec:org00d2d44}]{Notation}

	Let $[K]$ denote the set $\{1, \ldots, K \}$ for a positive integer $K$. Assume
	the data is comprised of iid replicates:

	\begin{equation*}
		\left\{{\covarrv}_{\obsindex},\, {\armrv}_{\obsindex},\,
		{\resprv}_{\obsindex} \right\}_{\obsindex = 1}^{\maxobsindex}
	\end{equation*}

	%	following the standard convention where

	$\covarrv_{\obsindex} \in \covarspace \subseteq
		\symbb{R}^{\dimarmparam}$ denotes the covariates (contexts)

	$\armrv_{ \obsindex} \in \armspace$ denotes the treatment arm (arm,
	intervention, action), and

	$\resprv_{ \obsindex} \in \symbb{R}$ denotes the response (reward)

	\vfill \pause

	We'll use the potential outcome framework and denote the potential outcome 	$\po(\armobs)$

	\vfill \pause
	I'll use the index $\asymindex$ when discussing asymptotics and $\obsindex$ when discussing finite samples.	I'll try to maintain consistency but might slip up.
\end{frame}


\begin{frame}{Operator notation}
	\begin{itemize}
		\item $\covarrv_1, \ldots, \covarrv_{\maxobsindex}$ is an iid random sample from a
		      fixed but unknown distribution $\Pop$
		\item $\genericfun$ is a generic parametric function indexed by $\theta \in \Theta$
		\item $\hat{\theta} \in \Theta$ is a random variable constructed from the sample
		      $\covarrv_1, \ldots, \covarrv_{\asymindex}$
	\end{itemize}
	\vfill \pause

	$\Pop$ denotes the probability measure:
	\begin{equation*}
		\Pop \genericfun(\covarrv; \hat{\theta}) = \int \genericfun(\covarobs;\,\widehat{\theta}) \dv
		\Pop(\covarobs))
	\end{equation*}

	\vfill \pause $\Pn$ denotes the corresponding empirical measure:

	\begin{equation*}
		\Pn \genericfun(\covarrv; \hat{\theta}) = \asymindex^{-1}\sum_{i =
			1}^{\asymindex} \genericfun(\covarobs_{i};\,\hat{\theta})
	\end{equation*}
	\vfill \pause

	$\leadsto$ denotes convergence in distribution.

	\vfill
\end{frame}

% \begin{frame}{Today's Focus}
% 	Single-stage

% 	Fixed policy

% 	No parametric assumptions
% \end{frame}


\section{Non-smooth Operators}
\begin{frame}{Nonregularity}
	Nonregular is the catch-all for when standard regularity conditions do
	not hold.
	\vfill \pause
	The general problem we'll be addressing is when the limiting
	distribution depends sharply on the parameter values.

	\vfill
	A common cause is a lack of
	\ddef{Smoothness}{
		A function $f$ is a smooth if it has continuous derivatives up to some
		desired order over some domain. The number of derivatives is problem-specific.
	}

	\vfill
	%	\tiny ``Continuously differentiable'' does not mean infinitely
	%	differentiable as a young me once confusedly thought.
\end{frame}

\begin{frame}{Examples of Nonregularity}
	Suppose $\covarrv_1, \ldots, \covarrv_{\asymindex}$ are iid copies of a random vector
	$\covarrv \in \mbbR^{p}$ drawn from an unknown distribution $P$. Let $\mu_0 = \Pop X
		= (\mu_{01}, \ldots, \mu_{0p})$

	\vfill \pause

	\textbf{Superefficient estimators}
	Define the estimator $\widetilde{\mu}_n$
	\begin{displaymath}
		\widetilde{\mu}_n = \begin{cases} \Pn X & \text { if } \Pn X \geq 1/4 \\
              0     & \text { if } \Pn X < 1/4\end{cases}
	\end{displaymath}

	\vfill \pause

	\textbf{Max of Means}
	Define $\theta_0$ as the component-wise maximum mean
	\begin{displaymath}
		\theta_0 = \maxsym_{j = 1}^p \mu_{0j} = \max_{j \in [p]} \mu_{0j}
	\end{displaymath}
\end{frame}

\begin{frame}{Is Nonregularity Avoidable?}

	``All \sout{happy families} regular estimators are alike; each \sout{unhappy
		family} nonregular estimator is unhappy in its own way.'' --- Markov,
	quoting Tolstoy\pause... maybe

	\vfill \pause
	For the superefficient estimator $\tilde{\mu}$ the form of the estimator, not
	the underlying estimand was the source of the nonregularity.

	\vfill \pause

	The nonregularity in value function inference is due to the nondifferentiability of the treatment
	policy/DTR, and this kind of nonregularity is unavoidable
	\footnote<4->{\fullcite{hirano2012Impossibility}}.
	\vfill
\end{frame}

\subsection{Max of Means Example}
\begin{frame}{Max of Means Limiting Distribution}

	Consider the estimators $\widehat{\mu}_{\asymindex} = \Pn \covarrv$  and $\widehat{\theta}_{\asymindex}$

	$$\widehat{\theta}_{\asymindex} = \maxsym_{j = 1}^p \widehat{\mu}_{\asymindex j}$$

	\begin{lemma}[Limiting Distribution of $\widehat{\theta}_{\asymindex} $]
		Define the set $\argmaxsetx{\mu_{0}} = \argmax_j \mu_{0j}$ and assume
		$\widehat{\mu}_n$ is regular $\rootn (\Pn - \Pop)X \convd \MVN(\zerovec, \Sigma)$. Then
		\begin{displaymath}
			\rootn (\widehat{\theta}_{\asymindex} - \theta_0) \convd \maxsym_{j \in \argmaxsetx{\mu_0}} Z_j
		\end{displaymath}
		where $Z \sim \MVN(\zerovec, \Sigma)$
	\end{lemma}

\end{frame}

\begin{frame}{Details of the Limiting Distribution}
	Define the event $\eventn = \indfunx{\max_{k \notin \argmaxsetx{\mu_0}}
			\widehat{\mu}_{nk} \geq \max_{j \in\argmaxsetx{\mu_0}} \widehat{\mu}_{nj}}$. Note that
	\begin{enumerate}
		\item  $\eventn = \op{1}$
		\item When $E_n$ holds the maximizer(s) is not in $\argmaxsetx{\mu_0}$ and vice versa
		      %When $E_n$ holds the maximizer(s) is not in $\argmaxsetx{\mu_0}$
		      %    and the converse is true for the complement $E_n^{\text{C}} = 1 - E_n $
	\end{enumerate}

	\begin{align*}
		\rootn & (\widehat{\theta}_{\asymindex} - \theta_0) =  \maxsym_{j = 1}^p
		\rootn(  \widehat{\mu}_{\asymindex j} -
		\theta_0)                                                                      \\
		       & = (1 - \eventn + \eventn) \maxsym_{j \in\argmaxsetx{\mu_0}}^p \rootn(
		\widehat{\mu}_{\asymindex j} - \theta_0)                                       \\
		       & =  \maxsym_{j \in\argmaxsetx{\mu_0}}^p \rootn(
		\widehat{\mu}_{\asymindex j} - \theta_0) + \eventn \left(\maxsym_{k \notin\argmaxsetx{\mu_0}}^p \rootn(
		\widehat{\mu}_{\asymindex k} - \theta_0)  - \maxsym_{j \in\argmaxsetx{\mu_0}}^p \rootn(
		\widehat{\mu}_{\asymindex j} - \theta_0)\right)
	\end{align*}
\end{frame}

\begin{frame}{Proof Concept}

	\large
	\begin{align*}
		\color{black} & \overbrace{\maxsym_{j \in\argmaxsetx{\mu_0}}^p \rootn(
			\widehat{\mu}_{\asymindex j} -
			\theta_0)}^{\mathclap{\substack{\text{\small The
		desired }                                                                 \\ \text{\small result}}}}  \\
		+             & \quad {\color{purple}\underbrace{\eventn \left(\maxsym_{k
				\notin\argmaxsetx{\mu_0}}^p \rootn( \widehat{\mu}_{\asymindex k} - \theta_0) -
			\maxsym_{j \in\argmaxsetx{\mu_0}}^p \rootn( \widehat{\mu}_{\asymindex j} -
			\theta_0)\right) }_{\mathclap{\text{\small A nuisance that's
				$\op{1}$}}}}
	\end{align*}
\end{frame}

\begin{frame}
	\begin{figure}
		\includegraphics[width=.9\textwidth]{figures/max_means_sim_plot}
	\end{figure}
\end{frame}

\subsection{Visual Introduction to Asymptotic Approaches}

\begin{frame}{PLACEHOLDER: Visual Examples of Approaches}
\end{frame}
\subsection{OWL}
\begin{frame}{OWL}
	\begin{figure}
		\includegraphics[width=.6\textwidth]{figures/how-to-draw-an-owl}
	\end{figure}
\end{frame}




% \begin{frame}{Abstract problem}
% 	Nonsmooth functional of a smooth function

% 	Approach overview:

% 	$m$ out of $n$ directly approximate the nonsmooth functional - let the
% 	perturbations in $m_n$ be larger than the perturbations from the
% 	non-regularlity

% 	$m$ is $o(n)$ i.e. as $m \to \infty$ $\frac{m}{n} \to 0$
% \end{frame}

\subsection{Asymptotic Aside}

\begin{frame}{What makes a good approximation?}
	Asymptotically valid does not guarantee a good approximation in finite
	samples.

	\vfill


	Recall that the limiting distribution of $\widehat{\theta}_n$ didn't depend on
	the differences in $\mu_0$ just the relevanat subelements of $\Sigma$ that are in $\argmaxsetx{\mu_0}$


	\vfill
	In finite samples, the sample size limits how large the differences
	need to be for us to distinguish them (remember the simulation plots).

	\vfill

	Our approximation ought to reflect our uncertainty about the set
	of 	maximizers.

	% \vfill pause
	% Ask yourself what kind of closeness would cause me to be nervous if my
	% statistic couldn't handle small perturbations of the model?
\end{frame}

\subsection{Local Alternatives}
\begin{frame}{The Local Alternative}
	Idea: allow the data generating model to change with $n$. The new models are
	comprised of a static part and a part that changes with $n$ which
	will go to zero in the limit.

	$$\mu_{0n} = \mu_0 + s \times h(n)$$
	\begin{itemize}
		\item Where $\mu_0, \,s \in \mbbR^{p}$ are both fixed.
		      \vfill
		\item $h(n)$ controls the perturbations. It is often, but not
		      exclusively, $n^{-1/2}$ depending on the problem.
	\end{itemize}
	\vfill

	When we're trying to recover regular estimators $n^{-1/2}$ will be the target

\end{frame}

\begin{frame}{Triangular Array}
	\begin{figure}
		\includegraphics[width=.85\textwidth]{figures/triangular-array}
	\end{figure}
\end{frame}

\section{Constructing Asymptotic Confidence Intervals}
\begin{frame}{Asymptotic Approach Overview}

	% Please add the following required packages to your document preamble:
	% \usepackage{booktabs}
	\begin{table}[]
		\begin{tabular}{@{}lcccc@{}}
			\toprule
			                   & \begin{tabular}[c]{@{}c@{}}Theoretical \\ Guarantees\end{tabular}
			                   & \begin{tabular}[c]{@{}c@{}}Easy to \\ Implement\end{tabular}
			                   & Conservative
			                   & \begin{tabular}[c]{@{}c@{}}Empirical \\ Performance\end{tabular}                                                       \\
			\midrule
			Projection sets    & $\checkmark^{+}$                                                  & \symbol{"2610}   & $\checkmark^{+}$ & $\checkmark$ \\
			Bounding           & $\checkmark^{+}$                                                  & \symbol{"2610}   & $\checkmark$     & \checkmark   \\
			\mon  \, Bootstrap & $\checkmark$
			                   & $\checkmark^{+}$                                                  & \symbol{"2610}   & \checkmark                      \\
			Regularization     & \textcolor{red}{!!}
			                   & $\checkmark$                                                      & \symbol{"2610}   & $\checkmark$                    \\
			The Jackknife      & \symbol{"2610}                                                    & $\checkmark^{+}$ &                  & $\checkmark$ \\
			\bottomrule
		\end{tabular}
	\end{table}

	\textcolor{red}{!!}	Regularization may induce infinite bias in certain scenarios.
\end{frame}


\subsection{Projections}
\begin{frame}{Projection Region Big Picture}
	Recall $\theta_0$ and $\mu_0$ from the max of means problem. What do we know?
	\begin{itemize}
		\item The empirical estimator $\widehat{\mu}_n = \Pn X$ is well-behaved
		      (regular)
		      \vfill \pause
		\item If we knew $\mu_0$ forming confidence intervals for ${\theta}_0$
		      would be simple% --- we'd know $\mu_{01}$ is the maximizer and
		      %construct a CI for $\mu_{01}$
	\end{itemize}
	\vfill \pause
	Solution:
	\begin{enumerate}
		\item Determine all plausible values of $\mu_0$ using the $(1- \alpha)$ CI
		\item For each plausible value of $\mu_0$, construct a CI for ${\theta}_0$
		      treating the plausible $\mu_0$ as fixed
		\item Take a union over over all of these CIs
	\end{enumerate}
	\vfill \pause
	Can be very conservative

	%	Particularly in the context of DTRs because
\end{frame}
\begin{frame}{Projection Confidence Set}
	Let $\waldset$ denote a $(1-\alpha)$ confidence set $\mu_0$. For concreteness, take
	the Wald CI

	$$\waldset = \waldsetdef$$

	\vfill \pause
	\ddef{Projection Confidence Set}{
		\begin{displaymath}
			\projset = \projsetdef
		\end{displaymath}
		is a valid confidence interval for $\theta_0$
	}
\end{frame}

\subsection{Bound-based CIs}
\begin{frame}{Bound-based CIs}
	Try to sandwich the nonsmooth functional between smooth upper and lower
	bounds.

	\vfill
	Fertile ground seems to looking at the $\inf$ and $\sup$ of the nonsmooth functional
\end{frame}

\subsection{\mon Bootstrap}

\begin{frame}{The $m$-out-of-$n$ Bootstrap}
	It's the bootstrap, but with subsamples of size $m_n$ instead of samples of
	size $n$
	\vfill
	$m_n$ is $o(n)$ i.e. as $m_n \to \infty$ $\frac{m}{n} \to 0$
	\vfill \pause

	This allows the \mon Bootstrap to directly approximates nonsmooth
	functionals by dark magic (even more magical than the standard bootstrap)

	\vfill \pause
	Intuition: bootstrap samples will tend to have the same characteristics as
	the original sample (very similar means, variances etc.). Subsamples get
	weird.
	\vfill \pause
	Caveat: Not as straightforwardly valid as Projection and Bounding approaches
	(modulo a certain definition of ``straightforward''), and can fail
	\footnote<4->{\fullcite{andrews2010Asymptotic}}.
\end{frame}
\section{Value Function Inference}

\subsection{Treatment Policy Notation}

\begin{frame}{Treatment Policy Notation}
	A policy (aka DTR, treatment rule) $\pol$\footnote{	Authors may write $\pol(\covarobs,
			\armobs)$, $\pol(\armobs \mid \covarobs)$, $\pol(\covarobs)$, or
		simply $\pol$ depending on what the author wishes to emphasize.
	} is a function which maps contexts to actions $\pol: \covarspace
		\mapsto \armspace$



	\vfill \pause
	Define the value of a policy $\pol$ as
	\begin{equation*}
		\val(\pol) \doteq \E_{\covarrv}[\po(\armobs = \pol(\covarrv))]
		%	\polval = \val(\pol) \doteq \E_{\covarrv}[\po(\armobs =\pol(\covarrv))]
	\end{equation*}

	\vfill \pause
	An optimal policy $\optpol$ is any policy that satisfies
	\begin{equation*}
		\val(\optpol) \geq \val(\pol) \qquad \text{for all }\pol \in
		\polset
		% \polvalopt = \val(\optpol) \geq \val(\pol) \qquad \text{for all }\pol \in \polset
	\end{equation*}

	\vfill \pause
	Denote the estimated optimal policy $\polhatn$, and for conciseness, assume
	that there is a unique maximizer for every covariate value.

\end{frame}

\begin{frame}{Value Functions}
	\begin{enumerate}
		\item (Conditional) Value of the estimated optimal policy

		      $$\val(\polhatn) = \valfundef = \valfundefop$$

		      \vfill \pause

		\item Expected Value of an estimated optimal policy
		      $$\valfunexpdef$$

		      \vfill \pause

		\item (Conditional\footnote{Not truly conditional because the
			      policy is not a RV})Value of the optimal policy (or, more broadly, any fixed policy)
		      $$\val(\optpol) = \valfunoptdef$$
	\end{enumerate}

	\vfill \pause
	These three will not generally be equivalent even asymptotically.
\end{frame}

\begin{frame}{Estimating the Value Function}
	There are two common approaches to estimating the value function:
	\vfill
	\begin{enumerate}
		\item Inverse Probability Weighting (IPW) / Importance Weighting

		\item Augmented Inverse Probability Weighting (AIPW) / Doubly Robust Estimation
	\end{enumerate}
	\vfill
\end{frame}
\begin{frame}{Other Distinctions in Evaluating Policies}

	Let $\histpol(\armobs \mid \covarobs)$ denote the policy that was used to
	assign treatment during the experiment and $\pol(\armobs \mid \covarobs)$ the
	policy we are intersested in evaluating.

	\begin{columns}[T]
		\begin{column}{.65\textwidth}
			\ddef{On/Off-Policy}{
				\begin{itemize}
					\setlength\itemsep{0.5em}
					\item[\textendash] On-policy evaluation: $\pol = \histpol$ for all
						$\covarobs$
					\item[\textendash] Off-policy evaluation: $\pol(\armobs \mid \covarobs) \neq
							\histpol(\armobs \mid \covarobs)$ for some $\covarobs$
						and $\armobs$.

						Requires additional assumptions. Ex:
						\[\wmax \doteq \esssup_{\obsindex \in \NN, \armobs \in \armspace,
								\covarobs \in \covarspace} \frac{\pi(\armobs \mid
								\covarobs)}{h_{\obsindex}(\armobs \mid \covarobs)} < \infty\]

						% $$\impwt =
						% 	\frac{\pol(\covarobs)}{\histpol(\covarobs)}$$
				\end{itemize}
			}
		\end{column}
		\pause
		\begin{column}{.35\textwidth}
			\ddef{Fixed or Estimated}{
				\begin{itemize}
					\setlength\itemsep{0.5em}
					\item[\textendash] Data-derived or estimated policy
					\item[\textendash] Fixed policy that's pre-specified before looking at
						the data.
				\end{itemize}
			}
		\end{column}%
	\end{columns}


\end{frame}


\begin{frame}{Setup Specifics}
	\begin{itemize}
		\item	Two arms $\armrv \in \{-1, 1\}$
		      \vfill

		\item $\polhatnx = \sign(\covarobs^{\trans}\widehat{\beta}_{\asymindex})$
		      \vfill

		\item Assume $\widehat{\Sigma}_n$ is a consistent estimator of the asymptotic variance of $\betahatn$
	\end{itemize}
	\vfill \pause

	Define $\nonregindclass = \nonregindclassdef$.
	\vfill

	We'll think of $\rootn(\Pn - \Popn)$ as a random element of $l^{\infty}(\mbbR^p)$
	\footnotesize
	See \fullcite{tsiatis2019Dynamic} for the assumptions. They're long and
	Donsker makes an appearance
\end{frame}

\begin{frame}{Joint Distribution Before Maximizing}

	\begin{displaymath}
		\rootn \begin{bmatrix}\Pn - \Pop_{\asymindex} \\
			\betahatn - \betao      \\
			(\Pn - \Pop_{\asymindex})\resprv \indfunx{\armrv \covarrv^{\trans}\betao
				> 0}\end{bmatrix} \convd \begin{pmatrix} \mbbT \\ \mbbZ \\
			\mbbW\end{pmatrix}
	\end{displaymath}

	where

	\begin{itemize}
		\item $\mbbT$ is a Brownian Bridge indexed by $\mbbR^p$
		\item $\mbbZ$ and $\mbbW$ are normal
	\end{itemize}
\end{frame}

\begin{frame}{Distribution after Maximizing}
	\begin{displaymath}
		\rootn (\valhatn (\betahatn) - \val(\betahatn)) \convd \mbbT(\mbbZ + s)
		+ \mbbW
	\end{displaymath}

	where $s$ is a local parameter. Again $\mbbT$ is a Brownian Bridge, and $\mbbZ$, $\mbbW$ normal.

	\vfill \pause
	Having $s$ in the limit shows this is nonregular\footnote{Note it wasn't in the
		joint distribution}.

	\vfill \pause
	We can construct a bound-based CI by
	\begin{enumerate}
		\item Partition $\covarspace$ into $\covarobs$s near the decision boundary
		      ($\covarobs^{\trans}\betahatn \approx 0$) and those far away
		      \vfill

		\item Take $\sup$/$\inf$ over local perturbations in the group close
		      to the boundary
	\end{enumerate}
	\vfill

\end{frame}
\begin{frame}{Upper Bound}
	\vfill

	Let $\tau_n$ be a sequence of tuning parameters that satisfies $\tau_n \to \infty$ and
	$\tau_n = o(n)$ as $n \to \infty$
	\vfill
	\large

	\begin{align*}
		U_n  = \sup_{\omega \in \mbbR^p} & \rootn(\Pn - \Popn)\resprv \indfunx{\armrv
			\covarrv^{\trans}\omega >
			0}\indfunx{\frac{\asymindex(\covarrv^{\trans}\betahatn)^2}{\covarrv^{\trans}\widehat{\Sigma}_n
		\covarrv} \leq \tau_{\asymindex}}                                               \\
		                                 & + \rootn(\Pn - \Popn)\resprv \indfunx{\armrv
			\covarrv^{\trans}\betahatn >
			0}\indfunx{\frac{\asymindex(\covarrv^{\trans}\betahatn)^2}{\covarrv^{\trans}\widehat{\Sigma}_n
				\covarrv} > \tau_{\asymindex}}
	\end{align*}
	\normalsize
	\vfill \pause

	Note that $\omega$ has been replaced with $\betahatn$ in the second line. Why?
	\vfill \pause
	Lower bound is analagous, replace $\sup$ with $\inf$
\end{frame}
% \begin{frame}{Life at the Boundary}
% 	The boundary is the source of the action

% 	In finite samples we can't identify observations that, in expectation, are
% 	near the boundary vs. on the boundary.

% 	This shows up in many proofs. Use the good old multiply by one trick using
% 	indicators for being on/not on the boundary.

% \end{frame}

\section{Avoiding Nonregularity}
\begin{frame}{Alternatives to Asymptotics}
	If the blow-up happens in the limit, what if we just don't take it to the limit?
\end{frame}

\begin{frame}{Finite-sample bounds}
	Similar in spirit to the asymptotic bound-based approach, but with
	$E$-processes and test	supermartingales playing the role of the nicely behaved functions.
	\vfill
	\[\text{Test supermartingale} \quad \E[Z_{\obsindex + 1} | Z_{\obsindex}] \leq
		Z_{\obsindex} \, \forall \obsindex \in \mbbN^+ \]

	\vfill \pause

	A test supermartingale $M_t$ is a non-negative supermartingale that under
	the null $P_0$ satisfies $\E_{P_0}[M_\obsindex] \leq 1$ at any time $\obsindex$

	\vfill \pause

	A nonnegative process $\prode{}{}$ is called an \emph{e-process} for $\symbf{P}$
	if there is a test martingale family $(M^P)_{P \in \symbf{P}}$ such that

	$$\prode{t}{} \leq M_{t}^{P} \text{ for every } P \in \symbf{P},  t \geq 0$$
\end{frame}

% \begin{frame}{Additional Notation of Note}
% 	Let $\histobs_{\obsindex}(\armrv_{\obsindex}, \covarrv_{\obsindex}) =
% 		\prob(\armrv_{\obsindex} = \armobs \mid \covarrv_{\obsindex} = \covarobs, \histspace_{t-1})$

% 	\[\impwtt \doteq \impwtdef \]
% \end{frame}

\begin{frame}{Assumptions in this Setting}
	\begin{itemize}
		\item $\resprv$ is bounded, and for convenience we'll assume $\resprv \in [0,1]$
		      \vfill
		\item $\polval_{\obsindex} \doteq \E_{\pol} [\resprv_{\obsindex} \mid
				      \history_{\obsindex-1}]$ and is adapted to the filtration $\history_{\obsindex-1}$
		      \vfill

		\item 	Exogenous treatment

		      $$\prob(\armrv_{\obsindex} \mid \histspace_{\obsindex - 1}) =
			      \prob(\armrv_{\obsindex} \mid \covarrv_{\obsindex})$$

		\item Finite importance weights
		      \[\wmax \doteq \esssup_{\obsindex \in \NN, \armobs \in \armspace, \covarobs \in
				      \covarspace} \frac{\pi(\armobs \mid \covarobs)}{h_{\obsindex}(\armobs \mid
				      \covarobs)} < \infty\]
	\end{itemize}






\end{frame}

% \begin{frame}{Assumptions for the method}
% \end{frame}

\begin{frame}{Confidence Sequences}
	\begin{definition}[Confidence Sequence]
		We say that a sequence of intervals $[L_\obsindex, U_\obsindex]_{\obsindex=1}^\infty$ is a confidence sequence for the parameter $\theta \in \RR$ if
		\begin{equation*}\label{eq:cs}
			\prob \left ( \forall \obsindex \in \NN,\ \theta \in [L_\obsindex, U_\obsindex] \right ) \geq 1-\alpha \end{equation*}
		or equivalently,
		\begin{equation*}
			\prob \left ( \exists \obsindex \in \NN : \theta \notin [L_\obsindex, U_\obsindex] \right ) \leq \alpha
		\end{equation*}
	\end{definition}

	\vfill \pause
	For comparison, recall that a $(1- \alpha)$ confidence interval (CI) satisfies

	$$\forall \obsindex \in \NN,\ \prob(\theta \in [L_\obsindex, U_\obsindex]) \geq 1-\alpha$$
\end{frame}

\begin{frame}{Key Result}
	Define the weighted rewards $\phi_\obsindex^\IWL \doteq \impwtt \resprv_\obsindex$ and $\phi_\obsindex^\IWU \doteq
		\impwtt(1-\resprv_\obsindex)$
	\vfill
	Let   $(\lambda_t^L(\candpolval))_{t=1}^\infty$ be any $[0, 1/\candpolval)$-valued
	predictable sequence

	\vfill
	\begin{equation}\label{eq:kmr-cs}
		L_t^\IW \doteq \inf\left \{ \candpolval \in [0, 1] : \prod_{i=1}^t \left ( 1 + \lambda_i^L(\candpolval) \cdot (\phi_t^\IWL - \candpolval) \right ) < \frac{1}{\alpha} \right \}
	\end{equation}
	forms a lower $(1-\alpha)$ confidence sequence for $\polval$, $\prob(\forall t \in \NN,\ \polval \geq L_t^\IW) \geq 1-\alpha$.
	\vfill \pause
	$\candpolval$ represents candidate policy value estimates
\end{frame}

\begin{frame}{Key Tools: Ville's Theoerem \& Inequality}
	For any discrete-time stochastic process $P$ an event $A$ has measure zero under
	$P$ if and only if there is a test martingale for $P$ that grows to
	infinity on all of $A$.

	\vfill \pause

	Moreover, $P(A) < \epsilon$ if and only if there is a test
	martingale for $P$ that exceeds $1/\epsilon$ on all of $A$.

	\vfill \pause
	\ddef{The Gambler's Ruin (Ville's Inequality)}{
		If $M$ is a test martingale for $P$ then
		$$\prob\left(\sup_t M_t \ge \alpha \right) \le \frac{1}{\alpha} \qquad \text{ for any }\alpha \ge 1$$
	}
\end{frame}

\begin{frame}{From Sequence to Interval}
	Suppose that all we care about is a $(1 - \alpha)$ CI after $\maxobsindex$
	observations.

	\vfill
	A CS is also trivially a CI at a fixed time, but the width of the interval
	will be wider than if we only needed to guarantee coverage at one point in
	time.

	\vfill \pause

	\begin{lemma}[The minimum and maximum bounds of a $1 - \alpha$ confidence
			sequence form a $1 - \alpha$ confidence interval.] Define lower and upper bounds, $L^{\text{CI}}$ and
		$L^{\text{CI}}$, as
		$$L^{\text{CI}} = \max_{\obsindex \leq \maxobsindex}
			L_{\obsindex}^{\text{CS}} \qquad \text{ and } U^{\text{CI}} = \max_{\obsindex \leq
				\maxobsindex} U_{\obsindex}^{\text{CS}}$$

		Then $(L^{\text{CI}},\, U^{\text{CI}})$ is a $(1 - \alpha)$ confidence
		interval for $\val(\pol)$
	\end{lemma}
\end{frame}

% \begin{frame}{What we didn't get to}
% 	Comparing multiple policies

% 	Off policy evaluation
% \end{frame}
\section{Where Next?}

\begin{frame}{Practical Improvements}
	Pre-testing/Screening for Projection Intervals
	\vfill

	Double bootstrap, other ways of selecting $m$ iteratively

	\vfill

	E-process Confidence Sequences
	\begin{itemize}
		\item Double robustness
		\item Trimming the observed rewards
		\item Empirical weights
	\end{itemize}
\end{frame}


\begin{frame}{Where to Start}
	\vfill

	Start with Chapter 10 of \cite{tsiatis2019Dynamic}
	\vfill

\end{frame}

\begin{frame}{General Theory -- Asymptotic}
	\vfill
	\begin{itemize}
		\item Chapter 3 of \cite{tsiatis2006Semiparametric}
		      \vfill
		\item Chapters 6 and 7 of \cite{vandervaart2000Asymptotic}
		      \vfill
		\item \cite{kosorok2008Introduction}
		      \vfill
		\item Important Paper: \cite{hirano2012Impossibility}
		      \vfill


		\item 	\cite{bibaut2021PostContextualBandit}
		      \vfill
	\end{itemize}
\end{frame}

\begin{frame}{Precision Medicine}
	\vfill
	\begin{itemize}
		\item \cite{laber2014Dynamic}
		      \vfill

		\item 	\cite{luedtke2016Statistical}
		      \vfill

		\item 	\cite{shi2022Statistical}

		\item \cite{hadad2021Confidence}
	\end{itemize}
	\vfill

\end{frame}

\begin{frame}{General Theory -- Non-asymptotic}
	\vfill
	\begin{itemize}
		\item \cite{waudby-smith2022Anytimevalid}
		      \vfill

		      \item\cite{howard2021Timeuniform}
	\end{itemize}
	\vfill

\end{frame}
\begin{frame}{Conformal Inference?}
	Stuff that might be relevant but I haven't looked into it yet.
	Prediction intervals not CIs. More cites because this list isn't
	as filtered.
	\begin{itemize}
		\item \fullcite{vovk2009Online}
		      \vfill
		\item \fullcite{chernozhukov2018Exact}
		      \vfill
		\item \fullcite{barber2021Predictive}
		      \vfill
		\item \fullcite{lei2021Conformal}
		      \vfill
		\item \fullcite{jin2023Sensitivity}
		      \vfill
	\end{itemize}
\end{frame}



\appendix
\printbibliography

\end{document}
%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: t
%%% End:
